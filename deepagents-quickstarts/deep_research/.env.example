# API settings for the news research agent
# Copy this file to .env and fill in your actual values

# llama.cpp server (OpenAI-compatible) configuration
LLAMA_API_KEY=local-llama
LLAMA_BASE_URL=http://localhost:8080/v1
# Set this to the model alias you configured for llama-server (default matches launch-llama.md)
LLAMA_MODEL=models/ggml/Qwen3-VL-30B-A3B-Instruct-UD-Q6_K_XL.gguf

# LangSmith API Key (required for LangGraph local server)
# Get your key at: https://smith.langchain.com/settings
LANGSMITH_API_KEY=lsv2_pt_your_api_key_here
